---
title: "Objects"
---

## Everything in a video is an object
Objects can be anything from a person, to a car, to the entire frame. Objects are the way Sieve **structures** videos.

<Example>
  <div class="flex items-center justify-center">
    <img class="w-full" src="/img/video-object.png" />
  </div>
</Example>

Objects have static properties that define them like a `class`. They also have `temporal` properties that can change over time such as `position` or some `state`.

<Example>
  <div class="flex items-center justify-center">
    <img class="w-full" src="/img/object-properties.png" />
  </div>
</Example>

#### Sample Objects
Sieve automatically tracks objects across frames which is why this information is retrievable in this way.

<CodeGroup>

```json Person
{
  "class": "person",
  "temporal": [
    {
      "bounding_box": {
        "x1": 5,
        "y1": 5,
        "x2": 10,
        "y2": 10
      },
      "action": "sitting",
      "frame_number": 1
    }
    ...
  ]
}
```

```json Frame
{
  "class": "frame",
  "temporal": [
    {
      "bounding_box": {
        "x1": 0,
        "y1": 0,
        "x2": 1920,
        "y2": 1080
      },
      "lighting": "dark",
      "frame_number": 1
    }
    ...
  ]
}
```

```json Audio
{
  "class": "audio",
  "transcription": "Hi I'm a person",
  "temporal": [
    {
      "bounding_box": {
        "x1": 0,
        "y1": 0,
        "x2": 1920,
        "y2": 1080
      },
      "frame_number": 1
    }
    ...
  ]
}
```

</CodeGroup>

### Motivation

Traditionally, videos possess no structure. They are just a series of frames. However, a core focus of Sieve is to help software teams ship ML features fast. This means an opinionation on the structure video possesses in order to provide a plug-and-play backend any team can immediately integrate into a web app, dashboard, etc.

The object structure enables a few things:
- **Search** - make queries in a MongoDB-like syntax to find videos and intervals within those videos that contain a match. Integrate queries directly into your web app or dashboard.
- **Output Artifacts** - apply visual effects such as background removal and rotoscoping to whole videos, specific intervals, crops of a frame, etc -- and retrieve masks, encoded videos, etc in a consistent format.
- **Operational Backend** - make corrections, additions, and removals to the defined structure to improve specific models over time. No need to build separate datasets.
